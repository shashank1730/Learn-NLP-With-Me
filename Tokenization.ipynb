{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "186fefb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\nalla\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\nalla\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\nalla\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\nalla\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (2024.7.24)\n",
      "Requirement already satisfied: tqdm in c:\\users\\nalla\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (4.66.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\nalla\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "888c0f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I genuinely believe that as time goes on, most of us will start ignoring those perfectly structured, polished messages.\n",
      "\n",
      "We’ll crave the unstructured, messy, kinda chaotic ones—the ones that feel human. The ones that sound like someone just poured their thoughts out without cleaning them up.\n",
      "\n",
      "And here’s the twist:\n",
      "It’s going to get harder for AI to mimic that kind of mess.\n",
      "\n",
      "Because true human messiness isn’t just random—it has intent, emotion, timing. It’s not just about bad grammar or missing punctuation. It’s about voice. Imperfection. Realness.\n",
      "\n",
      "That’s where things will get interesting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corpus = \"\"\"\n",
    "I genuinely believe that as time goes on, most of us will start ignoring those perfectly structured, polished messages.\n",
    "\n",
    "We’ll crave the unstructured, messy, kinda chaotic ones—the ones that feel human. The ones that sound like someone just poured their thoughts out without cleaning them up.\n",
    "\n",
    "And here’s the twist:\n",
    "It’s going to get harder for AI to mimic that kind of mess.\n",
    "\n",
    "Because true human messiness isn’t just random—it has intent, emotion, timing. It’s not just about bad grammar or missing punctuation. It’s about voice. Imperfection. Realness.\n",
    "\n",
    "That’s where things will get interesting.\n",
    "\"\"\"\n",
    "\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f98dfd1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nI genuinely believe that as time goes on, most of us will start ignoring those perfectly structured, polished messages.',\n",
       " 'We’ll crave the unstructured, messy, kinda chaotic ones—the ones that feel human.',\n",
       " 'The ones that sound like someone just poured their thoughts out without cleaning them up.',\n",
       " 'And here’s the twist:\\nIt’s going to get harder for AI to mimic that kind of mess.',\n",
       " 'Because true human messiness isn’t just random—it has intent, emotion, timing.',\n",
       " 'It’s not just about bad grammar or missing punctuation.',\n",
       " 'It’s about voice.',\n",
       " 'Imperfection.',\n",
       " 'Realness.',\n",
       " 'That’s where things will get interesting.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## To do Tokenization we have two methods\n",
    "#Sentence --> paragraphs\n",
    "#Sentence --> Words\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "docuemnts = sent_tokenize(corpus)\n",
    "docuemnts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d67d844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I genuinely believe that as time goes on, most of us will start ignoring those perfectly structured, polished messages.\n",
      "We’ll crave the unstructured, messy, kinda chaotic ones—the ones that feel human.\n",
      "The ones that sound like someone just poured their thoughts out without cleaning them up.\n",
      "And here’s the twist:\n",
      "It’s going to get harder for AI to mimic that kind of mess.\n",
      "Because true human messiness isn’t just random—it has intent, emotion, timing.\n",
      "It’s not just about bad grammar or missing punctuation.\n",
      "It’s about voice.\n",
      "Imperfection.\n",
      "Realness.\n",
      "That’s where things will get interesting.\n"
     ]
    }
   ],
   "source": [
    "for sentence in docuemnts:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbe2e156",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenization can be done in Two ways\n",
    "# 1.  Paragraphs --> Words\n",
    "# 2. Sentence --> Words\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68984185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'genuinely',\n",
       " 'believe',\n",
       " 'that',\n",
       " 'as',\n",
       " 'time',\n",
       " 'goes',\n",
       " 'on',\n",
       " ',',\n",
       " 'most',\n",
       " 'of',\n",
       " 'us',\n",
       " 'will',\n",
       " 'start',\n",
       " 'ignoring',\n",
       " 'those',\n",
       " 'perfectly',\n",
       " 'structured',\n",
       " ',',\n",
       " 'polished',\n",
       " 'messages',\n",
       " '.',\n",
       " 'We',\n",
       " '’',\n",
       " 'll',\n",
       " 'crave',\n",
       " 'the',\n",
       " 'unstructured',\n",
       " ',',\n",
       " 'messy',\n",
       " ',',\n",
       " 'kinda',\n",
       " 'chaotic',\n",
       " 'ones—the',\n",
       " 'ones',\n",
       " 'that',\n",
       " 'feel',\n",
       " 'human',\n",
       " '.',\n",
       " 'The',\n",
       " 'ones',\n",
       " 'that',\n",
       " 'sound',\n",
       " 'like',\n",
       " 'someone',\n",
       " 'just',\n",
       " 'poured',\n",
       " 'their',\n",
       " 'thoughts',\n",
       " 'out',\n",
       " 'without',\n",
       " 'cleaning',\n",
       " 'them',\n",
       " 'up',\n",
       " '.',\n",
       " 'And',\n",
       " 'here',\n",
       " '’',\n",
       " 's',\n",
       " 'the',\n",
       " 'twist',\n",
       " ':',\n",
       " 'It',\n",
       " '’',\n",
       " 's',\n",
       " 'going',\n",
       " 'to',\n",
       " 'get',\n",
       " 'harder',\n",
       " 'for',\n",
       " 'AI',\n",
       " 'to',\n",
       " 'mimic',\n",
       " 'that',\n",
       " 'kind',\n",
       " 'of',\n",
       " 'mess',\n",
       " '.',\n",
       " 'Because',\n",
       " 'true',\n",
       " 'human',\n",
       " 'messiness',\n",
       " 'isn',\n",
       " '’',\n",
       " 't',\n",
       " 'just',\n",
       " 'random—it',\n",
       " 'has',\n",
       " 'intent',\n",
       " ',',\n",
       " 'emotion',\n",
       " ',',\n",
       " 'timing',\n",
       " '.',\n",
       " 'It',\n",
       " '’',\n",
       " 's',\n",
       " 'not',\n",
       " 'just',\n",
       " 'about',\n",
       " 'bad',\n",
       " 'grammar',\n",
       " 'or',\n",
       " 'missing',\n",
       " 'punctuation',\n",
       " '.',\n",
       " 'It',\n",
       " '’',\n",
       " 's',\n",
       " 'about',\n",
       " 'voice',\n",
       " '.',\n",
       " 'Imperfection',\n",
       " '.',\n",
       " 'Realness',\n",
       " '.',\n",
       " 'That',\n",
       " '’',\n",
       " 's',\n",
       " 'where',\n",
       " 'things',\n",
       " 'will',\n",
       " 'get',\n",
       " 'interesting',\n",
       " '.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(corpus)\n",
    "# All the words are treated seperate even , and . \n",
    "# also if there is a word that have 's the \"'s\" is considered as one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33751271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'genuinely', 'believe', 'that', 'as', 'time', 'goes', 'on', ',', 'most', 'of', 'us', 'will', 'start', 'ignoring', 'those', 'perfectly', 'structured', ',', 'polished', 'messages', '.']\n",
      "['We', '’', 'll', 'crave', 'the', 'unstructured', ',', 'messy', ',', 'kinda', 'chaotic', 'ones—the', 'ones', 'that', 'feel', 'human', '.']\n",
      "['The', 'ones', 'that', 'sound', 'like', 'someone', 'just', 'poured', 'their', 'thoughts', 'out', 'without', 'cleaning', 'them', 'up', '.']\n",
      "['And', 'here', '’', 's', 'the', 'twist', ':', 'It', '’', 's', 'going', 'to', 'get', 'harder', 'for', 'AI', 'to', 'mimic', 'that', 'kind', 'of', 'mess', '.']\n",
      "['Because', 'true', 'human', 'messiness', 'isn', '’', 't', 'just', 'random—it', 'has', 'intent', ',', 'emotion', ',', 'timing', '.']\n",
      "['It', '’', 's', 'not', 'just', 'about', 'bad', 'grammar', 'or', 'missing', 'punctuation', '.']\n",
      "['It', '’', 's', 'about', 'voice', '.']\n",
      "['Imperfection', '.']\n",
      "['Realness', '.']\n",
      "['That', '’', 's', 'where', 'things', 'will', 'get', 'interesting', '.']\n"
     ]
    }
   ],
   "source": [
    "# Here each sentence is tokenized into words\n",
    "for sentence in docuemnts:\n",
    "    print(word_tokenize(sentence))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c707419c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75421074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'genuinely',\n",
       " 'believe',\n",
       " 'that',\n",
       " 'as',\n",
       " 'time',\n",
       " 'goes',\n",
       " 'on',\n",
       " ',',\n",
       " 'most',\n",
       " 'of',\n",
       " 'us',\n",
       " 'will',\n",
       " 'start',\n",
       " 'ignoring',\n",
       " 'those',\n",
       " 'perfectly',\n",
       " 'structured',\n",
       " ',',\n",
       " 'polished',\n",
       " 'messages',\n",
       " '.',\n",
       " 'We',\n",
       " '’',\n",
       " 'll',\n",
       " 'crave',\n",
       " 'the',\n",
       " 'unstructured',\n",
       " ',',\n",
       " 'messy',\n",
       " ',',\n",
       " 'kinda',\n",
       " 'chaotic',\n",
       " 'ones',\n",
       " '—',\n",
       " 'the',\n",
       " 'ones',\n",
       " 'that',\n",
       " 'feel',\n",
       " 'human',\n",
       " '.',\n",
       " 'The',\n",
       " 'ones',\n",
       " 'that',\n",
       " 'sound',\n",
       " 'like',\n",
       " 'someone',\n",
       " 'just',\n",
       " 'poured',\n",
       " 'their',\n",
       " 'thoughts',\n",
       " 'out',\n",
       " 'without',\n",
       " 'cleaning',\n",
       " 'them',\n",
       " 'up',\n",
       " '.',\n",
       " 'And',\n",
       " 'here',\n",
       " '’',\n",
       " 's',\n",
       " 'the',\n",
       " 'twist',\n",
       " ':',\n",
       " 'It',\n",
       " '’',\n",
       " 's',\n",
       " 'going',\n",
       " 'to',\n",
       " 'get',\n",
       " 'harder',\n",
       " 'for',\n",
       " 'AI',\n",
       " 'to',\n",
       " 'mimic',\n",
       " 'that',\n",
       " 'kind',\n",
       " 'of',\n",
       " 'mess',\n",
       " '.',\n",
       " 'Because',\n",
       " 'true',\n",
       " 'human',\n",
       " 'messiness',\n",
       " 'isn',\n",
       " '’',\n",
       " 't',\n",
       " 'just',\n",
       " 'random',\n",
       " '—',\n",
       " 'it',\n",
       " 'has',\n",
       " 'intent',\n",
       " ',',\n",
       " 'emotion',\n",
       " ',',\n",
       " 'timing',\n",
       " '.',\n",
       " 'It',\n",
       " '’',\n",
       " 's',\n",
       " 'not',\n",
       " 'just',\n",
       " 'about',\n",
       " 'bad',\n",
       " 'grammar',\n",
       " 'or',\n",
       " 'missing',\n",
       " 'punctuation',\n",
       " '.',\n",
       " 'It',\n",
       " '’',\n",
       " 's',\n",
       " 'about',\n",
       " 'voice',\n",
       " '.',\n",
       " 'Imperfection',\n",
       " '.',\n",
       " 'Realness',\n",
       " '.',\n",
       " 'That',\n",
       " '’',\n",
       " 's',\n",
       " 'where',\n",
       " 'things',\n",
       " 'will',\n",
       " 'get',\n",
       " 'interesting',\n",
       " '.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This one make sure even the \"'s\" is considered \",\" \"s\"\n",
    "wordpunct_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b526ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b1f4615",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TreebankWordTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5009ed6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'genuinely',\n",
       " 'believe',\n",
       " 'that',\n",
       " 'as',\n",
       " 'time',\n",
       " 'goes',\n",
       " 'on',\n",
       " ',',\n",
       " 'most',\n",
       " 'of',\n",
       " 'us',\n",
       " 'will',\n",
       " 'start',\n",
       " 'ignoring',\n",
       " 'those',\n",
       " 'perfectly',\n",
       " 'structured',\n",
       " ',',\n",
       " 'polished',\n",
       " 'messages.',\n",
       " 'We’ll',\n",
       " 'crave',\n",
       " 'the',\n",
       " 'unstructured',\n",
       " ',',\n",
       " 'messy',\n",
       " ',',\n",
       " 'kinda',\n",
       " 'chaotic',\n",
       " 'ones—the',\n",
       " 'ones',\n",
       " 'that',\n",
       " 'feel',\n",
       " 'human.',\n",
       " 'The',\n",
       " 'ones',\n",
       " 'that',\n",
       " 'sound',\n",
       " 'like',\n",
       " 'someone',\n",
       " 'just',\n",
       " 'poured',\n",
       " 'their',\n",
       " 'thoughts',\n",
       " 'out',\n",
       " 'without',\n",
       " 'cleaning',\n",
       " 'them',\n",
       " 'up.',\n",
       " 'And',\n",
       " 'here’s',\n",
       " 'the',\n",
       " 'twist',\n",
       " ':',\n",
       " 'It’s',\n",
       " 'going',\n",
       " 'to',\n",
       " 'get',\n",
       " 'harder',\n",
       " 'for',\n",
       " 'AI',\n",
       " 'to',\n",
       " 'mimic',\n",
       " 'that',\n",
       " 'kind',\n",
       " 'of',\n",
       " 'mess.',\n",
       " 'Because',\n",
       " 'true',\n",
       " 'human',\n",
       " 'messiness',\n",
       " 'isn’t',\n",
       " 'just',\n",
       " 'random—it',\n",
       " 'has',\n",
       " 'intent',\n",
       " ',',\n",
       " 'emotion',\n",
       " ',',\n",
       " 'timing.',\n",
       " 'It’s',\n",
       " 'not',\n",
       " 'just',\n",
       " 'about',\n",
       " 'bad',\n",
       " 'grammar',\n",
       " 'or',\n",
       " 'missing',\n",
       " 'punctuation.',\n",
       " 'It’s',\n",
       " 'about',\n",
       " 'voice.',\n",
       " 'Imperfection.',\n",
       " 'Realness.',\n",
       " 'That’s',\n",
       " 'where',\n",
       " 'things',\n",
       " 'will',\n",
       " 'get',\n",
       " 'interesting',\n",
       " '.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All fullstops are treated as part of the word only the last full stop is considered as seperate word\n",
    "tokenizer.tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1135db0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
